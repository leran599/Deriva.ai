[2025-07-06T15:38:17.283+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.download_and_process manual__2025-07-06T15:38:10.058241+00:00 map_index=3 [queued]>
[2025-07-06T15:38:17.290+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.download_and_process manual__2025-07-06T15:38:10.058241+00:00 map_index=3 [queued]>
[2025-07-06T15:38:17.290+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-06T15:38:17.373+0000] {taskinstance.py:1380} INFO - Executing <Mapped(_PythonDecoratedOperator): download_and_process> on 2025-07-06 15:38:10.058241+00:00
[2025-07-06T15:38:17.377+0000] {standard_task_runner.py:57} INFO - Started process 323 to run task
[2025-07-06T15:38:17.381+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'download_and_process', 'manual__2025-07-06T15:38:10.058241+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmponi30gl4', '--map-index', '3']
[2025-07-06T15:38:17.387+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask download_and_process
[2025-07-06T15:38:17.474+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T15:38:17.578+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.download_and_process manual__2025-07-06T15:38:10.058241+00:00 map_index=3 [running]> on host 2331dcd11242
[2025-07-06T15:38:18.492+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='download_and_process' AIRFLOW_CTX_EXECUTION_DATE='2025-07-06T15:38:10.058241+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-06T15:38:10.058241+00:00'
[2025-07-06T15:38:18.493+0000] {logging_mixin.py:151} INFO - Starting download of 2023.csv.gz
[2025-07-06T15:38:18.497+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-06T15:38:18.497+0000] {logging_mixin.py:151} INFO - Downloading from: https://www.ncei.noaa.gov//pub/data/ghcn/daily/by_year/2023.csv.gz
[2025-07-06T15:38:18.499+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-06T15:42:58.401+0000] {logging_mixin.py:151} INFO - Download completed for 2023.csv.gz, size: 8489719 bytes
[2025-07-06T15:42:58.403+0000] {logging_mixin.py:151} INFO - Processing 2023.csv.gz in chunks of 10000 rows...
[2025-07-06T15:42:58.426+0000] {logging_mixin.py:151} INFO - Processed chunk 1, total rows so far: 10000
[2025-07-06T15:42:58.668+0000] {logging_mixin.py:151} INFO - Processed chunk 11, total rows so far: 110000
[2025-07-06T15:42:58.987+0000] {logging_mixin.py:151} INFO - Processed chunk 21, total rows so far: 210000
[2025-07-06T15:42:59.564+0000] {logging_mixin.py:151} INFO - Processed chunk 31, total rows so far: 310000
[2025-07-06T15:43:00.489+0000] {logging_mixin.py:151} INFO - Processed chunk 41, total rows so far: 410000
[2025-07-06T15:43:00.889+0000] {logging_mixin.py:151} INFO - Processed chunk 51, total rows so far: 510000
[2025-07-06T15:43:01.290+0000] {logging_mixin.py:151} INFO - Processed chunk 61, total rows so far: 610000
[2025-07-06T15:43:01.788+0000] {logging_mixin.py:151} INFO - Processed chunk 71, total rows so far: 710000
[2025-07-06T15:43:02.179+0000] {logging_mixin.py:151} INFO - Processed chunk 81, total rows so far: 810000
[2025-07-06T15:43:02.670+0000] {logging_mixin.py:151} INFO - Processed chunk 91, total rows so far: 910000
[2025-07-06T15:43:03.068+0000] {logging_mixin.py:151} INFO - Processed chunk 101, total rows so far: 1010000
[2025-07-06T15:43:03.477+0000] {logging_mixin.py:151} INFO - Processed chunk 111, total rows so far: 1110000
[2025-07-06T15:43:03.967+0000] {logging_mixin.py:151} INFO - Processed chunk 121, total rows so far: 1210000
[2025-07-06T15:43:04.473+0000] {logging_mixin.py:151} INFO - Processed chunk 131, total rows so far: 1310000
[2025-07-06T15:43:04.971+0000] {logging_mixin.py:151} INFO - Processed chunk 141, total rows so far: 1410000
[2025-07-06T15:43:05.371+0000] {logging_mixin.py:151} INFO - Processed chunk 151, total rows so far: 1510000
[2025-07-06T15:43:05.866+0000] {logging_mixin.py:151} INFO - Processed chunk 161, total rows so far: 1610000
[2025-07-06T15:43:06.273+0000] {logging_mixin.py:151} INFO - Processed chunk 171, total rows so far: 1710000
[2025-07-06T15:43:06.670+0000] {logging_mixin.py:151} INFO - Processed chunk 181, total rows so far: 1810000
[2025-07-06T15:43:06.672+0000] {logging_mixin.py:151} INFO - Error downloading 2023.csv.gz: Compressed file ended before the end-of-stream marker was reached
[2025-07-06T15:43:06.672+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/weather_data_pipeline.py", line 96, in download_and_process
    for chunk_num, chunk_df in enumerate(pd.read_csv(f, header=None,
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1624, in __next__
    return self.get_chunk()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1733, in get_chunk
    return self.read(nrows=size)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1704, in read
    ) = self._engine.read(  # type: ignore[attr-defined]
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 234, in read
    chunks = self._reader.read_low_memory(nrows)
  File "pandas/_libs/parsers.pyx", line 826, in pandas._libs.parsers.TextReader.read_low_memory
  File "pandas/_libs/parsers.pyx", line 875, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 850, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 861, in pandas._libs.parsers.TextReader._check_tokenize_status
  File "pandas/_libs/parsers.pyx", line 2021, in pandas._libs.parsers.raise_parser_error
  File "/usr/local/lib/python3.8/_compression.py", line 68, in readinto
    data = self.read(len(byte_view))
  File "/usr/local/lib/python3.8/gzip.py", line 498, in read
    raise EOFError("Compressed file ended before the "
EOFError: Compressed file ended before the end-of-stream marker was reached
[2025-07-06T15:43:06.677+0000] {taskinstance.py:1398} INFO - Marking task as UP_FOR_RETRY. dag_id=weather_data_pipeline, task_id=download_and_process, map_index=3, execution_date=20250706T153810, start_date=20250706T153817, end_date=20250706T154306
[2025-07-06T15:43:06.762+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 7 for task download_and_process (Compressed file ended before the end-of-stream marker was reached; 323)
[2025-07-06T15:43:06.784+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2025-07-06T15:43:06.868+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
