[2025-07-06T15:38:17.177+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.download_and_process manual__2025-07-06T15:38:10.058241+00:00 map_index=0 [queued]>
[2025-07-06T15:38:17.184+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.download_and_process manual__2025-07-06T15:38:10.058241+00:00 map_index=0 [queued]>
[2025-07-06T15:38:17.185+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-06T15:38:17.193+0000] {taskinstance.py:1380} INFO - Executing <Mapped(_PythonDecoratedOperator): download_and_process> on 2025-07-06 15:38:10.058241+00:00
[2025-07-06T15:38:17.271+0000] {standard_task_runner.py:57} INFO - Started process 322 to run task
[2025-07-06T15:38:17.276+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'download_and_process', 'manual__2025-07-06T15:38:10.058241+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmpe4f0ss5p', '--map-index', '0']
[2025-07-06T15:38:17.280+0000] {standard_task_runner.py:85} INFO - Job 5: Subtask download_and_process
[2025-07-06T15:38:17.294+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-06T15:38:17.395+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.download_and_process manual__2025-07-06T15:38:10.058241+00:00 map_index=0 [running]> on host 2331dcd11242
[2025-07-06T15:38:18.489+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='download_and_process' AIRFLOW_CTX_EXECUTION_DATE='2025-07-06T15:38:10.058241+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-06T15:38:10.058241+00:00'
[2025-07-06T15:38:18.490+0000] {logging_mixin.py:151} INFO - Starting download of 2020.csv.gz
[2025-07-06T15:38:18.493+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-06T15:38:18.493+0000] {logging_mixin.py:151} INFO - Downloading from: https://www.ncei.noaa.gov//pub/data/ghcn/daily/by_year/2020.csv.gz
[2025-07-06T15:38:18.496+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-06T15:42:58.461+0000] {logging_mixin.py:151} INFO - Download completed for 2020.csv.gz, size: 16360743 bytes
[2025-07-06T15:42:58.462+0000] {logging_mixin.py:151} INFO - Processing 2020.csv.gz in chunks of 10000 rows...
[2025-07-06T15:42:58.476+0000] {logging_mixin.py:151} INFO - Processed chunk 1, total rows so far: 10000
[2025-07-06T15:42:58.768+0000] {logging_mixin.py:151} INFO - Processed chunk 11, total rows so far: 110000
[2025-07-06T15:42:59.174+0000] {logging_mixin.py:151} INFO - Processed chunk 21, total rows so far: 210000
[2025-07-06T15:42:59.777+0000] {logging_mixin.py:151} INFO - Processed chunk 31, total rows so far: 310000
[2025-07-06T15:43:00.673+0000] {logging_mixin.py:151} INFO - Processed chunk 41, total rows so far: 410000
[2025-07-06T15:43:00.983+0000] {logging_mixin.py:151} INFO - Processed chunk 51, total rows so far: 510000
[2025-07-06T15:43:01.386+0000] {logging_mixin.py:151} INFO - Processed chunk 61, total rows so far: 610000
[2025-07-06T15:43:01.972+0000] {logging_mixin.py:151} INFO - Processed chunk 71, total rows so far: 710000
[2025-07-06T15:43:02.276+0000] {logging_mixin.py:151} INFO - Processed chunk 81, total rows so far: 810000
[2025-07-06T15:43:02.768+0000] {logging_mixin.py:151} INFO - Processed chunk 91, total rows so far: 910000
[2025-07-06T15:43:03.082+0000] {logging_mixin.py:151} INFO - Processed chunk 101, total rows so far: 1010000
[2025-07-06T15:43:03.572+0000] {logging_mixin.py:151} INFO - Processed chunk 111, total rows so far: 1110000
[2025-07-06T15:43:04.065+0000] {logging_mixin.py:151} INFO - Processed chunk 121, total rows so far: 1210000
[2025-07-06T15:43:04.576+0000] {logging_mixin.py:151} INFO - Processed chunk 131, total rows so far: 1310000
[2025-07-06T15:43:05.073+0000] {logging_mixin.py:151} INFO - Processed chunk 141, total rows so far: 1410000
[2025-07-06T15:43:05.478+0000] {logging_mixin.py:151} INFO - Processed chunk 151, total rows so far: 1510000
[2025-07-06T15:43:05.882+0000] {logging_mixin.py:151} INFO - Processed chunk 161, total rows so far: 1610000
[2025-07-06T15:43:06.288+0000] {logging_mixin.py:151} INFO - Processed chunk 171, total rows so far: 1710000
[2025-07-06T15:43:06.763+0000] {logging_mixin.py:151} INFO - Processed chunk 181, total rows so far: 1810000
[2025-07-06T15:43:06.987+0000] {logging_mixin.py:151} INFO - Processed chunk 191, total rows so far: 1910000
[2025-07-06T15:43:07.281+0000] {logging_mixin.py:151} INFO - Processed chunk 201, total rows so far: 2010000
[2025-07-06T15:43:07.579+0000] {logging_mixin.py:151} INFO - Processed chunk 211, total rows so far: 2110000
[2025-07-06T15:43:07.802+0000] {logging_mixin.py:151} INFO - Processed chunk 221, total rows so far: 2210000
[2025-07-06T15:43:07.994+0000] {logging_mixin.py:151} INFO - Processed chunk 231, total rows so far: 2310000
[2025-07-06T15:43:08.177+0000] {logging_mixin.py:151} INFO - Processed chunk 241, total rows so far: 2410000
[2025-07-06T15:43:08.294+0000] {logging_mixin.py:151} INFO - Processed chunk 251, total rows so far: 2510000
[2025-07-06T15:43:08.477+0000] {logging_mixin.py:151} INFO - Processed chunk 261, total rows so far: 2610000
[2025-07-06T15:43:08.602+0000] {logging_mixin.py:151} INFO - Processed chunk 271, total rows so far: 2710000
[2025-07-06T15:43:08.782+0000] {logging_mixin.py:151} INFO - Processed chunk 281, total rows so far: 2810000
[2025-07-06T15:43:08.910+0000] {logging_mixin.py:151} INFO - Processed chunk 291, total rows so far: 2910000
[2025-07-06T15:43:09.091+0000] {logging_mixin.py:151} INFO - Processed chunk 301, total rows so far: 3010000
[2025-07-06T15:43:09.263+0000] {logging_mixin.py:151} INFO - Processed chunk 311, total rows so far: 3110000
[2025-07-06T15:43:09.387+0000] {logging_mixin.py:151} INFO - Processed chunk 321, total rows so far: 3210000
[2025-07-06T15:43:09.568+0000] {logging_mixin.py:151} INFO - Processed chunk 331, total rows so far: 3310000
[2025-07-06T15:43:09.699+0000] {logging_mixin.py:151} INFO - Processed chunk 341, total rows so far: 3410000
[2025-07-06T15:43:09.801+0000] {logging_mixin.py:151} INFO - Error downloading 2020.csv.gz: Compressed file ended before the end-of-stream marker was reached
[2025-07-06T15:43:09.801+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/weather_data_pipeline.py", line 96, in download_and_process
    for chunk_num, chunk_df in enumerate(pd.read_csv(f, header=None,
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1624, in __next__
    return self.get_chunk()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1733, in get_chunk
    return self.read(nrows=size)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1704, in read
    ) = self._engine.read(  # type: ignore[attr-defined]
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 234, in read
    chunks = self._reader.read_low_memory(nrows)
  File "pandas/_libs/parsers.pyx", line 826, in pandas._libs.parsers.TextReader.read_low_memory
  File "pandas/_libs/parsers.pyx", line 875, in pandas._libs.parsers.TextReader._read_rows
  File "pandas/_libs/parsers.pyx", line 850, in pandas._libs.parsers.TextReader._tokenize_rows
  File "pandas/_libs/parsers.pyx", line 861, in pandas._libs.parsers.TextReader._check_tokenize_status
  File "pandas/_libs/parsers.pyx", line 2021, in pandas._libs.parsers.raise_parser_error
  File "/usr/local/lib/python3.8/_compression.py", line 68, in readinto
    data = self.read(len(byte_view))
  File "/usr/local/lib/python3.8/gzip.py", line 498, in read
    raise EOFError("Compressed file ended before the "
EOFError: Compressed file ended before the end-of-stream marker was reached
[2025-07-06T15:43:09.812+0000] {taskinstance.py:1398} INFO - Marking task as UP_FOR_RETRY. dag_id=weather_data_pipeline, task_id=download_and_process, map_index=0, execution_date=20250706T153810, start_date=20250706T153817, end_date=20250706T154309
[2025-07-06T15:43:09.819+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 5 for task download_and_process (Compressed file ended before the end-of-stream marker was reached; 322)
[2025-07-06T15:43:09.830+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2025-07-06T15:43:09.871+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
