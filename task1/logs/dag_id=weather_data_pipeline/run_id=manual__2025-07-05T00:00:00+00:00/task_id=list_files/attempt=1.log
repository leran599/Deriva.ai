[2025-07-05T10:00:42.185+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T10:00:42.189+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T10:00:42.189+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-05T10:00:42.194+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): list_files> on 2025-07-05 00:00:00+00:00
[2025-07-05T10:00:42.196+0000] {standard_task_runner.py:57} INFO - Started process 408 to run task
[2025-07-05T10:00:42.198+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'list_files', 'manual__2025-07-05T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmphd88tblz']
[2025-07-05T10:00:42.200+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask list_files
[2025-07-05T10:00:42.208+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-05T10:00:42.225+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [running]> on host 50a81e38c03c
[2025-07-05T10:00:42.354+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='list_files' AIRFLOW_CTX_EXECUTION_DATE='2025-07-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-05T00:00:00+00:00'
[2025-07-05T10:00:42.358+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-05T10:00:44.998+0000] {python.py:194} INFO - Done. Returned value was: []
[2025-07-05T10:00:45.016+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "xcom_pkey"
DETAIL:  Key (dag_run_id, task_id, map_index, key)=(3, list_files, -1, return_value) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2477, in xcom_push
    XCom.set(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom.py", line 273, in set
    session.flush()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3589, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "xcom_pkey"
DETAIL:  Key (dag_run_id, task_id, map_index, key)=(3, list_files, -1, return_value) already exists.

[SQL: INSERT INTO xcom (dag_run_id, task_id, map_index, key, dag_id, run_id, value, timestamp) VALUES (%(dag_run_id)s, %(task_id)s, %(map_index)s, %(key)s, %(dag_id)s, %(run_id)s, %(value)s, %(timestamp)s)]
[parameters: {'dag_run_id': 3, 'task_id': 'list_files', 'map_index': -1, 'key': 'return_value', 'dag_id': 'weather_data_pipeline', 'run_id': 'manual__2025-07-05T00:00:00+00:00', 'value': <psycopg2.extensions.Binary object at 0xffff5e729f90>, 'timestamp': datetime.datetime(2025, 7, 5, 10, 0, 45, 13754, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2025-07-05T10:00:45.026+0000] {taskinstance.py:1398} INFO - Marking task as UP_FOR_RETRY. dag_id=weather_data_pipeline, task_id=list_files, execution_date=20250705T000000, start_date=20250705T100042, end_date=20250705T100045
[2025-07-05T10:00:45.034+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 6 for task list_files ((psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "xcom_pkey"
DETAIL:  Key (dag_run_id, task_id, map_index, key)=(3, list_files, -1, return_value) already exists.

[SQL: INSERT INTO xcom (dag_run_id, task_id, map_index, key, dag_id, run_id, value, timestamp) VALUES (%(dag_run_id)s, %(task_id)s, %(map_index)s, %(key)s, %(dag_id)s, %(run_id)s, %(value)s, %(timestamp)s)]
[parameters: {'dag_run_id': 3, 'task_id': 'list_files', 'map_index': -1, 'key': 'return_value', 'dag_id': 'weather_data_pipeline', 'run_id': 'manual__2025-07-05T00:00:00+00:00', 'value': <psycopg2.extensions.Binary object at 0xffff5e729f90>, 'timestamp': datetime.datetime(2025, 7, 5, 10, 0, 45, 13754, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 408)
[2025-07-05T10:00:45.048+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2025-07-05T10:00:45.065+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-05T10:02:44.717+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T10:02:44.721+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T10:02:44.721+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-05T10:02:44.727+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): list_files> on 2025-07-05 00:00:00+00:00
[2025-07-05T10:02:44.729+0000] {standard_task_runner.py:57} INFO - Started process 454 to run task
[2025-07-05T10:02:44.731+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'list_files', 'manual__2025-07-05T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmpd3gtmb9b']
[2025-07-05T10:02:44.732+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask list_files
[2025-07-05T10:02:44.739+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-05T10:02:44.751+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [running]> on host 50a81e38c03c
[2025-07-05T10:02:44.863+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='list_files' AIRFLOW_CTX_EXECUTION_DATE='2025-07-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-05T00:00:00+00:00'
[2025-07-05T10:02:44.866+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-05T10:02:45.625+0000] {python.py:194} INFO - Done. Returned value was: []
[2025-07-05T10:02:45.649+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=list_files, execution_date=20250705T000000, start_date=20250705T100244, end_date=20250705T100245
[2025-07-05T10:02:45.679+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-05T10:02:45.691+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-05T10:10:05.550+0000] {taskinstance.py:1147} INFO - Dependencies not met for <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [success]>, dependency 'Task Instance State' FAILED: Task is in the 'success' state.
[2025-07-05T10:10:05.551+0000] {local_task_job_runner.py:154} INFO - Task is not able to be run
[2025-07-05T10:40:39.190+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T10:40:39.194+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T10:40:39.194+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-05T10:40:39.199+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): list_files> on 2025-07-05 00:00:00+00:00
[2025-07-05T10:40:39.201+0000] {standard_task_runner.py:57} INFO - Started process 1109 to run task
[2025-07-05T10:40:39.203+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'list_files', 'manual__2025-07-05T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmp6u189mmv']
[2025-07-05T10:40:39.205+0000] {standard_task_runner.py:85} INFO - Job 33: Subtask list_files
[2025-07-05T10:40:39.211+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-05T10:40:39.226+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [running]> on host 50a81e38c03c
[2025-07-05T10:40:39.338+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='list_files' AIRFLOW_CTX_EXECUTION_DATE='2025-07-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-05T00:00:00+00:00'
[2025-07-05T10:40:39.342+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-05T10:40:40.028+0000] {logging_mixin.py:151} INFO - Response status: 200
[2025-07-05T10:40:40.028+0000] {logging_mixin.py:151} INFO - Response length: 37759
[2025-07-05T10:40:40.028+0000] {logging_mixin.py:151} INFO - Response preview: <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
 <head>
  <title>Index of /pub/data/ghcn/daily/by_year</title>
 </head>
 <body>
<h1>Index of /pub/data/ghcn/daily/by_year</h1>
  <table>
   <tr><th><a href="?C=N;O=D">Name</a></th><th><a href="?C=M;O=A">Last modified</a></th><th><a href="?C=S;O=A">Size</a></th><th><a href="?C=D;O=A">Description</a></th></tr>
   <tr><th colspan="4"><hr></th></tr>
<tr><td><a href="/pub/data/ghcn/daily/">Parent Directory</a></td><td>&nbsp;</td><td align
[2025-07-05T10:40:40.029+0000] {logging_mixin.py:151} INFO - Raw HTML sample: r>
<tr><td><a href="2020.csv.gz">2020.cs
[2025-07-05T10:40:40.029+0000] {logging_mixin.py:151} INFO - All links found: ['1750.csv.gz', '1763.csv.gz', '1764.csv.gz', '1765.csv.gz', '1766.csv.gz', '1767.csv.gz', '1768.csv.gz', '1769.csv.gz', '1770.csv.gz', '1771.csv.gz', '1772.csv.gz', '1773.csv.gz', '1774.csv.gz', '1775.csv.gz', '1776.csv.gz', '1777.csv.gz', '1778.csv.gz', '1779.csv.gz', '1780.csv.gz', '1781.csv.gz', '1782.csv.gz', '1783.csv.gz', '1784.csv.gz', '1785.csv.gz', '1786.csv.gz', '1787.csv.gz', '1788.csv.gz', '1789.csv.gz', '1790.csv.gz', '1791.csv.gz', '1792.csv.gz', '1793.csv.gz', '1794.csv.gz', '1795.csv.gz', '1796.csv.gz', '1797.csv.gz', '1798.csv.gz', '1799.csv.gz', '1800.csv.gz', '1801.csv.gz', '1802.csv.gz', '1803.csv.gz', '1804.csv.gz', '1805.csv.gz', '1806.csv.gz', '1807.csv.gz', '1808.csv.gz', '1809.csv.gz', '1810.csv.gz', '1811.csv.gz', '1812.csv.gz', '1813.csv.gz', '1814.csv.gz', '1815.csv.gz', '1816.csv.gz', '1817.csv.gz', '1818.csv.gz', '1819.csv.gz', '1820.csv.gz', '1821.csv.gz', '1822.csv.gz', '1823.csv.gz', '1824.csv.gz', '1825.csv.gz', '1826.csv.gz', '1827.csv.gz', '1828.csv.gz', '1829.csv.gz', '1830.csv.gz', '1831.csv.gz', '1832.csv.gz', '1833.csv.gz', '1834.csv.gz', '1835.csv.gz', '1836.csv.gz', '1837.csv.gz', '1838.csv.gz', '1839.csv.gz', '1840.csv.gz', '1841.csv.gz', '1842.csv.gz', '1843.csv.gz', '1844.csv.gz', '1845.csv.gz', '1846.csv.gz', '1847.csv.gz', '1848.csv.gz', '1849.csv.gz', '1850.csv.gz', '1851.csv.gz', '1852.csv.gz', '1853.csv.gz', '1854.csv.gz', '1855.csv.gz', '1856.csv.gz', '1857.csv.gz', '1858.csv.gz', '1859.csv.gz', '1860.csv.gz', '1861.csv.gz', '1862.csv.gz', '1863.csv.gz', '1864.csv.gz', '1865.csv.gz', '1866.csv.gz', '1867.csv.gz', '1868.csv.gz', '1869.csv.gz', '1870.csv.gz', '1871.csv.gz', '1872.csv.gz', '1873.csv.gz', '1874.csv.gz', '1875.csv.gz', '1876.csv.gz', '1877.csv.gz', '1878.csv.gz', '1879.csv.gz', '1880.csv.gz', '1881.csv.gz', '1882.csv.gz', '1883.csv.gz', '1884.csv.gz', '1885.csv.gz', '1886.csv.gz', '1887.csv.gz', '1888.csv.gz', '1889.csv.gz', '1890.csv.gz', '1891.csv.gz', '1892.csv.gz', '1893.csv.gz', '1894.csv.gz', '1895.csv.gz', '1896.csv.gz', '1897.csv.gz', '1898.csv.gz', '1899.csv.gz', '1900.csv.gz', '1901.csv.gz', '1902.csv.gz', '1903.csv.gz', '1904.csv.gz', '1905.csv.gz', '1906.csv.gz', '1907.csv.gz', '1908.csv.gz', '1909.csv.gz', '1910.csv.gz', '1911.csv.gz', '1912.csv.gz', '1913.csv.gz', '1914.csv.gz', '1915.csv.gz', '1916.csv.gz', '1917.csv.gz', '1918.csv.gz', '1919.csv.gz', '1920.csv.gz', '1921.csv.gz', '1922.csv.gz', '1923.csv.gz', '1924.csv.gz', '1925.csv.gz', '1926.csv.gz', '1927.csv.gz', '1928.csv.gz', '1929.csv.gz', '1930.csv.gz', '1931.csv.gz', '1932.csv.gz', '1933.csv.gz', '1934.csv.gz', '1935.csv.gz', '1936.csv.gz', '1937.csv.gz', '1938.csv.gz', '1939.csv.gz', '1940.csv.gz', '1941.csv.gz', '1942.csv.gz', '1943.csv.gz', '1944.csv.gz', '1945.csv.gz', '1946.csv.gz', '1947.csv.gz', '1948.csv.gz', '1949.csv.gz', '1950.csv.gz', '1951.csv.gz', '1952.csv.gz', '1953.csv.gz', '1954.csv.gz', '1955.csv.gz', '1956.csv.gz', '1957.csv.gz', '1958.csv.gz', '1959.csv.gz', '1960.csv.gz', '1961.csv.gz', '1962.csv.gz', '1963.csv.gz', '1964.csv.gz', '1965.csv.gz', '1966.csv.gz', '1967.csv.gz', '1968.csv.gz', '1969.csv.gz', '1970.csv.gz', '1971.csv.gz', '1972.csv.gz', '1973.csv.gz', '1974.csv.gz', '1975.csv.gz', '1976.csv.gz', '1977.csv.gz', '1978.csv.gz', '1979.csv.gz', '1980.csv.gz', '1981.csv.gz', '1982.csv.gz', '1983.csv.gz', '1984.csv.gz', '1985.csv.gz', '1986.csv.gz', '1987.csv.gz', '1988.csv.gz', '1989.csv.gz', '1990.csv.gz', '1991.csv.gz', '1992.csv.gz', '1993.csv.gz', '1994.csv.gz', '1995.csv.gz', '1996.csv.gz', '1997.csv.gz', '1998.csv.gz', '1999.csv.gz', '2000.csv.gz', '2001.csv.gz', '2002.csv.gz', '2003.csv.gz', '2004.csv.gz', '2005.csv.gz', '2006.csv.gz', '2007.csv.gz', '2008.csv.gz', '2009.csv.gz', '2010.csv.gz', '2011.csv.gz', '2012.csv.gz', '2013.csv.gz', '2014.csv.gz', '2015.csv.gz', '2016.csv.gz', '2017.csv.gz', '2018.csv.gz', '2019.csv.gz', '2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz', '2024.csv.gz', '2025.csv.gz']
[2025-07-05T10:40:40.029+0000] {logging_mixin.py:151} INFO - Looking for years: [2020, 2021, 2022, 2023]
[2025-07-05T10:40:40.029+0000] {logging_mixin.py:151} INFO - Filtered links: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T10:40:40.030+0000] {python.py:194} INFO - Done. Returned value was: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T10:40:40.044+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=list_files, execution_date=20250705T000000, start_date=20250705T104039, end_date=20250705T104040
[2025-07-05T10:40:40.068+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-05T10:40:40.082+0000] {taskinstance.py:2776} INFO - 4 downstream tasks scheduled from follow-on schedule check
[2025-07-05T10:47:36.560+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T10:47:36.564+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T10:47:36.564+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-05T10:47:36.570+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): list_files> on 2025-07-05 00:00:00+00:00
[2025-07-05T10:47:36.572+0000] {standard_task_runner.py:57} INFO - Started process 1245 to run task
[2025-07-05T10:47:36.574+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'list_files', 'manual__2025-07-05T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmpg26l1w9v']
[2025-07-05T10:47:36.576+0000] {standard_task_runner.py:85} INFO - Job 40: Subtask list_files
[2025-07-05T10:47:36.582+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-05T10:47:36.596+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [running]> on host 50a81e38c03c
[2025-07-05T10:47:36.710+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='list_files' AIRFLOW_CTX_EXECUTION_DATE='2025-07-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-05T00:00:00+00:00'
[2025-07-05T10:47:36.713+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-05T10:47:37.417+0000] {logging_mixin.py:151} INFO - Response status: 200
[2025-07-05T10:47:37.418+0000] {logging_mixin.py:151} INFO - Response length: 37759
[2025-07-05T10:47:37.418+0000] {logging_mixin.py:151} INFO - Response preview: <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
 <head>
  <title>Index of /pub/data/ghcn/daily/by_year</title>
 </head>
 <body>
<h1>Index of /pub/data/ghcn/daily/by_year</h1>
  <table>
   <tr><th><a href="?C=N;O=D">Name</a></th><th><a href="?C=M;O=A">Last modified</a></th><th><a href="?C=S;O=A">Size</a></th><th><a href="?C=D;O=A">Description</a></th></tr>
   <tr><th colspan="4"><hr></th></tr>
<tr><td><a href="/pub/data/ghcn/daily/">Parent Directory</a></td><td>&nbsp;</td><td align
[2025-07-05T10:47:37.418+0000] {logging_mixin.py:151} INFO - Raw HTML sample: r>
<tr><td><a href="2020.csv.gz">2020.cs
[2025-07-05T10:47:37.418+0000] {logging_mixin.py:151} INFO - All links found: ['1750.csv.gz', '1763.csv.gz', '1764.csv.gz', '1765.csv.gz', '1766.csv.gz', '1767.csv.gz', '1768.csv.gz', '1769.csv.gz', '1770.csv.gz', '1771.csv.gz', '1772.csv.gz', '1773.csv.gz', '1774.csv.gz', '1775.csv.gz', '1776.csv.gz', '1777.csv.gz', '1778.csv.gz', '1779.csv.gz', '1780.csv.gz', '1781.csv.gz', '1782.csv.gz', '1783.csv.gz', '1784.csv.gz', '1785.csv.gz', '1786.csv.gz', '1787.csv.gz', '1788.csv.gz', '1789.csv.gz', '1790.csv.gz', '1791.csv.gz', '1792.csv.gz', '1793.csv.gz', '1794.csv.gz', '1795.csv.gz', '1796.csv.gz', '1797.csv.gz', '1798.csv.gz', '1799.csv.gz', '1800.csv.gz', '1801.csv.gz', '1802.csv.gz', '1803.csv.gz', '1804.csv.gz', '1805.csv.gz', '1806.csv.gz', '1807.csv.gz', '1808.csv.gz', '1809.csv.gz', '1810.csv.gz', '1811.csv.gz', '1812.csv.gz', '1813.csv.gz', '1814.csv.gz', '1815.csv.gz', '1816.csv.gz', '1817.csv.gz', '1818.csv.gz', '1819.csv.gz', '1820.csv.gz', '1821.csv.gz', '1822.csv.gz', '1823.csv.gz', '1824.csv.gz', '1825.csv.gz', '1826.csv.gz', '1827.csv.gz', '1828.csv.gz', '1829.csv.gz', '1830.csv.gz', '1831.csv.gz', '1832.csv.gz', '1833.csv.gz', '1834.csv.gz', '1835.csv.gz', '1836.csv.gz', '1837.csv.gz', '1838.csv.gz', '1839.csv.gz', '1840.csv.gz', '1841.csv.gz', '1842.csv.gz', '1843.csv.gz', '1844.csv.gz', '1845.csv.gz', '1846.csv.gz', '1847.csv.gz', '1848.csv.gz', '1849.csv.gz', '1850.csv.gz', '1851.csv.gz', '1852.csv.gz', '1853.csv.gz', '1854.csv.gz', '1855.csv.gz', '1856.csv.gz', '1857.csv.gz', '1858.csv.gz', '1859.csv.gz', '1860.csv.gz', '1861.csv.gz', '1862.csv.gz', '1863.csv.gz', '1864.csv.gz', '1865.csv.gz', '1866.csv.gz', '1867.csv.gz', '1868.csv.gz', '1869.csv.gz', '1870.csv.gz', '1871.csv.gz', '1872.csv.gz', '1873.csv.gz', '1874.csv.gz', '1875.csv.gz', '1876.csv.gz', '1877.csv.gz', '1878.csv.gz', '1879.csv.gz', '1880.csv.gz', '1881.csv.gz', '1882.csv.gz', '1883.csv.gz', '1884.csv.gz', '1885.csv.gz', '1886.csv.gz', '1887.csv.gz', '1888.csv.gz', '1889.csv.gz', '1890.csv.gz', '1891.csv.gz', '1892.csv.gz', '1893.csv.gz', '1894.csv.gz', '1895.csv.gz', '1896.csv.gz', '1897.csv.gz', '1898.csv.gz', '1899.csv.gz', '1900.csv.gz', '1901.csv.gz', '1902.csv.gz', '1903.csv.gz', '1904.csv.gz', '1905.csv.gz', '1906.csv.gz', '1907.csv.gz', '1908.csv.gz', '1909.csv.gz', '1910.csv.gz', '1911.csv.gz', '1912.csv.gz', '1913.csv.gz', '1914.csv.gz', '1915.csv.gz', '1916.csv.gz', '1917.csv.gz', '1918.csv.gz', '1919.csv.gz', '1920.csv.gz', '1921.csv.gz', '1922.csv.gz', '1923.csv.gz', '1924.csv.gz', '1925.csv.gz', '1926.csv.gz', '1927.csv.gz', '1928.csv.gz', '1929.csv.gz', '1930.csv.gz', '1931.csv.gz', '1932.csv.gz', '1933.csv.gz', '1934.csv.gz', '1935.csv.gz', '1936.csv.gz', '1937.csv.gz', '1938.csv.gz', '1939.csv.gz', '1940.csv.gz', '1941.csv.gz', '1942.csv.gz', '1943.csv.gz', '1944.csv.gz', '1945.csv.gz', '1946.csv.gz', '1947.csv.gz', '1948.csv.gz', '1949.csv.gz', '1950.csv.gz', '1951.csv.gz', '1952.csv.gz', '1953.csv.gz', '1954.csv.gz', '1955.csv.gz', '1956.csv.gz', '1957.csv.gz', '1958.csv.gz', '1959.csv.gz', '1960.csv.gz', '1961.csv.gz', '1962.csv.gz', '1963.csv.gz', '1964.csv.gz', '1965.csv.gz', '1966.csv.gz', '1967.csv.gz', '1968.csv.gz', '1969.csv.gz', '1970.csv.gz', '1971.csv.gz', '1972.csv.gz', '1973.csv.gz', '1974.csv.gz', '1975.csv.gz', '1976.csv.gz', '1977.csv.gz', '1978.csv.gz', '1979.csv.gz', '1980.csv.gz', '1981.csv.gz', '1982.csv.gz', '1983.csv.gz', '1984.csv.gz', '1985.csv.gz', '1986.csv.gz', '1987.csv.gz', '1988.csv.gz', '1989.csv.gz', '1990.csv.gz', '1991.csv.gz', '1992.csv.gz', '1993.csv.gz', '1994.csv.gz', '1995.csv.gz', '1996.csv.gz', '1997.csv.gz', '1998.csv.gz', '1999.csv.gz', '2000.csv.gz', '2001.csv.gz', '2002.csv.gz', '2003.csv.gz', '2004.csv.gz', '2005.csv.gz', '2006.csv.gz', '2007.csv.gz', '2008.csv.gz', '2009.csv.gz', '2010.csv.gz', '2011.csv.gz', '2012.csv.gz', '2013.csv.gz', '2014.csv.gz', '2015.csv.gz', '2016.csv.gz', '2017.csv.gz', '2018.csv.gz', '2019.csv.gz', '2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz', '2024.csv.gz', '2025.csv.gz']
[2025-07-05T10:47:37.418+0000] {logging_mixin.py:151} INFO - Looking for years: [2020, 2021, 2022, 2023]
[2025-07-05T10:47:37.418+0000] {logging_mixin.py:151} INFO - Filtered links: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T10:47:37.419+0000] {python.py:194} INFO - Done. Returned value was: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T10:47:37.434+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=list_files, execution_date=20250705T000000, start_date=20250705T104736, end_date=20250705T104737
[2025-07-05T10:47:37.447+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-05T10:47:37.459+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-05T10:56:21.172+0000] {taskinstance.py:1147} INFO - Dependencies not met for <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [success]>, dependency 'Task Instance State' FAILED: Task is in the 'success' state.
[2025-07-05T10:56:21.172+0000] {local_task_job_runner.py:154} INFO - Task is not able to be run
[2025-07-05T11:13:43.452+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T11:13:43.456+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T11:13:43.456+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-05T11:13:43.462+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): list_files> on 2025-07-05 00:00:00+00:00
[2025-07-05T11:13:43.465+0000] {standard_task_runner.py:57} INFO - Started process 248 to run task
[2025-07-05T11:13:43.467+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'list_files', 'manual__2025-07-05T00:00:00+00:00', '--job-id', '54', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmpzv8e1x6m']
[2025-07-05T11:13:43.469+0000] {standard_task_runner.py:85} INFO - Job 54: Subtask list_files
[2025-07-05T11:13:43.479+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-05T11:13:43.500+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [running]> on host e91311d291b4
[2025-07-05T11:13:43.645+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='list_files' AIRFLOW_CTX_EXECUTION_DATE='2025-07-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-05T00:00:00+00:00'
[2025-07-05T11:13:43.649+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-05T11:13:44.616+0000] {logging_mixin.py:151} INFO - Response status: 200
[2025-07-05T11:13:44.619+0000] {logging_mixin.py:151} INFO - Response length: 37759
[2025-07-05T11:13:44.619+0000] {logging_mixin.py:151} INFO - Response preview: <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
 <head>
  <title>Index of /pub/data/ghcn/daily/by_year</title>
 </head>
 <body>
<h1>Index of /pub/data/ghcn/daily/by_year</h1>
  <table>
   <tr><th><a href="?C=N;O=D">Name</a></th><th><a href="?C=M;O=A">Last modified</a></th><th><a href="?C=S;O=A">Size</a></th><th><a href="?C=D;O=A">Description</a></th></tr>
   <tr><th colspan="4"><hr></th></tr>
<tr><td><a href="/pub/data/ghcn/daily/">Parent Directory</a></td><td>&nbsp;</td><td align
[2025-07-05T11:13:44.620+0000] {logging_mixin.py:151} INFO - Raw HTML sample: r>
<tr><td><a href="2020.csv.gz">2020.cs
[2025-07-05T11:13:44.621+0000] {logging_mixin.py:151} INFO - All links found: ['1750.csv.gz', '1763.csv.gz', '1764.csv.gz', '1765.csv.gz', '1766.csv.gz', '1767.csv.gz', '1768.csv.gz', '1769.csv.gz', '1770.csv.gz', '1771.csv.gz', '1772.csv.gz', '1773.csv.gz', '1774.csv.gz', '1775.csv.gz', '1776.csv.gz', '1777.csv.gz', '1778.csv.gz', '1779.csv.gz', '1780.csv.gz', '1781.csv.gz', '1782.csv.gz', '1783.csv.gz', '1784.csv.gz', '1785.csv.gz', '1786.csv.gz', '1787.csv.gz', '1788.csv.gz', '1789.csv.gz', '1790.csv.gz', '1791.csv.gz', '1792.csv.gz', '1793.csv.gz', '1794.csv.gz', '1795.csv.gz', '1796.csv.gz', '1797.csv.gz', '1798.csv.gz', '1799.csv.gz', '1800.csv.gz', '1801.csv.gz', '1802.csv.gz', '1803.csv.gz', '1804.csv.gz', '1805.csv.gz', '1806.csv.gz', '1807.csv.gz', '1808.csv.gz', '1809.csv.gz', '1810.csv.gz', '1811.csv.gz', '1812.csv.gz', '1813.csv.gz', '1814.csv.gz', '1815.csv.gz', '1816.csv.gz', '1817.csv.gz', '1818.csv.gz', '1819.csv.gz', '1820.csv.gz', '1821.csv.gz', '1822.csv.gz', '1823.csv.gz', '1824.csv.gz', '1825.csv.gz', '1826.csv.gz', '1827.csv.gz', '1828.csv.gz', '1829.csv.gz', '1830.csv.gz', '1831.csv.gz', '1832.csv.gz', '1833.csv.gz', '1834.csv.gz', '1835.csv.gz', '1836.csv.gz', '1837.csv.gz', '1838.csv.gz', '1839.csv.gz', '1840.csv.gz', '1841.csv.gz', '1842.csv.gz', '1843.csv.gz', '1844.csv.gz', '1845.csv.gz', '1846.csv.gz', '1847.csv.gz', '1848.csv.gz', '1849.csv.gz', '1850.csv.gz', '1851.csv.gz', '1852.csv.gz', '1853.csv.gz', '1854.csv.gz', '1855.csv.gz', '1856.csv.gz', '1857.csv.gz', '1858.csv.gz', '1859.csv.gz', '1860.csv.gz', '1861.csv.gz', '1862.csv.gz', '1863.csv.gz', '1864.csv.gz', '1865.csv.gz', '1866.csv.gz', '1867.csv.gz', '1868.csv.gz', '1869.csv.gz', '1870.csv.gz', '1871.csv.gz', '1872.csv.gz', '1873.csv.gz', '1874.csv.gz', '1875.csv.gz', '1876.csv.gz', '1877.csv.gz', '1878.csv.gz', '1879.csv.gz', '1880.csv.gz', '1881.csv.gz', '1882.csv.gz', '1883.csv.gz', '1884.csv.gz', '1885.csv.gz', '1886.csv.gz', '1887.csv.gz', '1888.csv.gz', '1889.csv.gz', '1890.csv.gz', '1891.csv.gz', '1892.csv.gz', '1893.csv.gz', '1894.csv.gz', '1895.csv.gz', '1896.csv.gz', '1897.csv.gz', '1898.csv.gz', '1899.csv.gz', '1900.csv.gz', '1901.csv.gz', '1902.csv.gz', '1903.csv.gz', '1904.csv.gz', '1905.csv.gz', '1906.csv.gz', '1907.csv.gz', '1908.csv.gz', '1909.csv.gz', '1910.csv.gz', '1911.csv.gz', '1912.csv.gz', '1913.csv.gz', '1914.csv.gz', '1915.csv.gz', '1916.csv.gz', '1917.csv.gz', '1918.csv.gz', '1919.csv.gz', '1920.csv.gz', '1921.csv.gz', '1922.csv.gz', '1923.csv.gz', '1924.csv.gz', '1925.csv.gz', '1926.csv.gz', '1927.csv.gz', '1928.csv.gz', '1929.csv.gz', '1930.csv.gz', '1931.csv.gz', '1932.csv.gz', '1933.csv.gz', '1934.csv.gz', '1935.csv.gz', '1936.csv.gz', '1937.csv.gz', '1938.csv.gz', '1939.csv.gz', '1940.csv.gz', '1941.csv.gz', '1942.csv.gz', '1943.csv.gz', '1944.csv.gz', '1945.csv.gz', '1946.csv.gz', '1947.csv.gz', '1948.csv.gz', '1949.csv.gz', '1950.csv.gz', '1951.csv.gz', '1952.csv.gz', '1953.csv.gz', '1954.csv.gz', '1955.csv.gz', '1956.csv.gz', '1957.csv.gz', '1958.csv.gz', '1959.csv.gz', '1960.csv.gz', '1961.csv.gz', '1962.csv.gz', '1963.csv.gz', '1964.csv.gz', '1965.csv.gz', '1966.csv.gz', '1967.csv.gz', '1968.csv.gz', '1969.csv.gz', '1970.csv.gz', '1971.csv.gz', '1972.csv.gz', '1973.csv.gz', '1974.csv.gz', '1975.csv.gz', '1976.csv.gz', '1977.csv.gz', '1978.csv.gz', '1979.csv.gz', '1980.csv.gz', '1981.csv.gz', '1982.csv.gz', '1983.csv.gz', '1984.csv.gz', '1985.csv.gz', '1986.csv.gz', '1987.csv.gz', '1988.csv.gz', '1989.csv.gz', '1990.csv.gz', '1991.csv.gz', '1992.csv.gz', '1993.csv.gz', '1994.csv.gz', '1995.csv.gz', '1996.csv.gz', '1997.csv.gz', '1998.csv.gz', '1999.csv.gz', '2000.csv.gz', '2001.csv.gz', '2002.csv.gz', '2003.csv.gz', '2004.csv.gz', '2005.csv.gz', '2006.csv.gz', '2007.csv.gz', '2008.csv.gz', '2009.csv.gz', '2010.csv.gz', '2011.csv.gz', '2012.csv.gz', '2013.csv.gz', '2014.csv.gz', '2015.csv.gz', '2016.csv.gz', '2017.csv.gz', '2018.csv.gz', '2019.csv.gz', '2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz', '2024.csv.gz', '2025.csv.gz']
[2025-07-05T11:13:44.622+0000] {logging_mixin.py:151} INFO - Looking for years: [2020, 2021, 2022, 2023]
[2025-07-05T11:13:44.622+0000] {logging_mixin.py:151} INFO - Filtered links: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T11:13:44.624+0000] {python.py:194} INFO - Done. Returned value was: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T11:13:44.653+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=list_files, execution_date=20250705T000000, start_date=20250705T111343, end_date=20250705T111344
[2025-07-05T11:13:44.704+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-05T11:13:44.720+0000] {taskinstance.py:2776} INFO - 4 downstream tasks scheduled from follow-on schedule check
[2025-07-05T11:18:18.426+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T11:18:18.429+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T11:18:18.429+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-05T11:18:18.434+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): list_files> on 2025-07-05 00:00:00+00:00
[2025-07-05T11:18:18.437+0000] {standard_task_runner.py:57} INFO - Started process 273 to run task
[2025-07-05T11:18:18.438+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'list_files', 'manual__2025-07-05T00:00:00+00:00', '--job-id', '60', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmpetfakknn']
[2025-07-05T11:18:18.440+0000] {standard_task_runner.py:85} INFO - Job 60: Subtask list_files
[2025-07-05T11:18:18.446+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-05T11:18:18.459+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [running]> on host 139cae0cce46
[2025-07-05T11:18:18.570+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='list_files' AIRFLOW_CTX_EXECUTION_DATE='2025-07-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-05T00:00:00+00:00'
[2025-07-05T11:18:18.573+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-05T11:18:19.278+0000] {logging_mixin.py:151} INFO - Response status: 200
[2025-07-05T11:18:19.286+0000] {logging_mixin.py:151} INFO - Response length: 37759
[2025-07-05T11:18:19.286+0000] {logging_mixin.py:151} INFO - Response preview: <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
 <head>
  <title>Index of /pub/data/ghcn/daily/by_year</title>
 </head>
 <body>
<h1>Index of /pub/data/ghcn/daily/by_year</h1>
  <table>
   <tr><th><a href="?C=N;O=D">Name</a></th><th><a href="?C=M;O=A">Last modified</a></th><th><a href="?C=S;O=A">Size</a></th><th><a href="?C=D;O=A">Description</a></th></tr>
   <tr><th colspan="4"><hr></th></tr>
<tr><td><a href="/pub/data/ghcn/daily/">Parent Directory</a></td><td>&nbsp;</td><td align
[2025-07-05T11:18:19.287+0000] {logging_mixin.py:151} INFO - Raw HTML sample: r>
<tr><td><a href="2020.csv.gz">2020.cs
[2025-07-05T11:18:19.287+0000] {logging_mixin.py:151} INFO - All links found: ['1750.csv.gz', '1763.csv.gz', '1764.csv.gz', '1765.csv.gz', '1766.csv.gz', '1767.csv.gz', '1768.csv.gz', '1769.csv.gz', '1770.csv.gz', '1771.csv.gz', '1772.csv.gz', '1773.csv.gz', '1774.csv.gz', '1775.csv.gz', '1776.csv.gz', '1777.csv.gz', '1778.csv.gz', '1779.csv.gz', '1780.csv.gz', '1781.csv.gz', '1782.csv.gz', '1783.csv.gz', '1784.csv.gz', '1785.csv.gz', '1786.csv.gz', '1787.csv.gz', '1788.csv.gz', '1789.csv.gz', '1790.csv.gz', '1791.csv.gz', '1792.csv.gz', '1793.csv.gz', '1794.csv.gz', '1795.csv.gz', '1796.csv.gz', '1797.csv.gz', '1798.csv.gz', '1799.csv.gz', '1800.csv.gz', '1801.csv.gz', '1802.csv.gz', '1803.csv.gz', '1804.csv.gz', '1805.csv.gz', '1806.csv.gz', '1807.csv.gz', '1808.csv.gz', '1809.csv.gz', '1810.csv.gz', '1811.csv.gz', '1812.csv.gz', '1813.csv.gz', '1814.csv.gz', '1815.csv.gz', '1816.csv.gz', '1817.csv.gz', '1818.csv.gz', '1819.csv.gz', '1820.csv.gz', '1821.csv.gz', '1822.csv.gz', '1823.csv.gz', '1824.csv.gz', '1825.csv.gz', '1826.csv.gz', '1827.csv.gz', '1828.csv.gz', '1829.csv.gz', '1830.csv.gz', '1831.csv.gz', '1832.csv.gz', '1833.csv.gz', '1834.csv.gz', '1835.csv.gz', '1836.csv.gz', '1837.csv.gz', '1838.csv.gz', '1839.csv.gz', '1840.csv.gz', '1841.csv.gz', '1842.csv.gz', '1843.csv.gz', '1844.csv.gz', '1845.csv.gz', '1846.csv.gz', '1847.csv.gz', '1848.csv.gz', '1849.csv.gz', '1850.csv.gz', '1851.csv.gz', '1852.csv.gz', '1853.csv.gz', '1854.csv.gz', '1855.csv.gz', '1856.csv.gz', '1857.csv.gz', '1858.csv.gz', '1859.csv.gz', '1860.csv.gz', '1861.csv.gz', '1862.csv.gz', '1863.csv.gz', '1864.csv.gz', '1865.csv.gz', '1866.csv.gz', '1867.csv.gz', '1868.csv.gz', '1869.csv.gz', '1870.csv.gz', '1871.csv.gz', '1872.csv.gz', '1873.csv.gz', '1874.csv.gz', '1875.csv.gz', '1876.csv.gz', '1877.csv.gz', '1878.csv.gz', '1879.csv.gz', '1880.csv.gz', '1881.csv.gz', '1882.csv.gz', '1883.csv.gz', '1884.csv.gz', '1885.csv.gz', '1886.csv.gz', '1887.csv.gz', '1888.csv.gz', '1889.csv.gz', '1890.csv.gz', '1891.csv.gz', '1892.csv.gz', '1893.csv.gz', '1894.csv.gz', '1895.csv.gz', '1896.csv.gz', '1897.csv.gz', '1898.csv.gz', '1899.csv.gz', '1900.csv.gz', '1901.csv.gz', '1902.csv.gz', '1903.csv.gz', '1904.csv.gz', '1905.csv.gz', '1906.csv.gz', '1907.csv.gz', '1908.csv.gz', '1909.csv.gz', '1910.csv.gz', '1911.csv.gz', '1912.csv.gz', '1913.csv.gz', '1914.csv.gz', '1915.csv.gz', '1916.csv.gz', '1917.csv.gz', '1918.csv.gz', '1919.csv.gz', '1920.csv.gz', '1921.csv.gz', '1922.csv.gz', '1923.csv.gz', '1924.csv.gz', '1925.csv.gz', '1926.csv.gz', '1927.csv.gz', '1928.csv.gz', '1929.csv.gz', '1930.csv.gz', '1931.csv.gz', '1932.csv.gz', '1933.csv.gz', '1934.csv.gz', '1935.csv.gz', '1936.csv.gz', '1937.csv.gz', '1938.csv.gz', '1939.csv.gz', '1940.csv.gz', '1941.csv.gz', '1942.csv.gz', '1943.csv.gz', '1944.csv.gz', '1945.csv.gz', '1946.csv.gz', '1947.csv.gz', '1948.csv.gz', '1949.csv.gz', '1950.csv.gz', '1951.csv.gz', '1952.csv.gz', '1953.csv.gz', '1954.csv.gz', '1955.csv.gz', '1956.csv.gz', '1957.csv.gz', '1958.csv.gz', '1959.csv.gz', '1960.csv.gz', '1961.csv.gz', '1962.csv.gz', '1963.csv.gz', '1964.csv.gz', '1965.csv.gz', '1966.csv.gz', '1967.csv.gz', '1968.csv.gz', '1969.csv.gz', '1970.csv.gz', '1971.csv.gz', '1972.csv.gz', '1973.csv.gz', '1974.csv.gz', '1975.csv.gz', '1976.csv.gz', '1977.csv.gz', '1978.csv.gz', '1979.csv.gz', '1980.csv.gz', '1981.csv.gz', '1982.csv.gz', '1983.csv.gz', '1984.csv.gz', '1985.csv.gz', '1986.csv.gz', '1987.csv.gz', '1988.csv.gz', '1989.csv.gz', '1990.csv.gz', '1991.csv.gz', '1992.csv.gz', '1993.csv.gz', '1994.csv.gz', '1995.csv.gz', '1996.csv.gz', '1997.csv.gz', '1998.csv.gz', '1999.csv.gz', '2000.csv.gz', '2001.csv.gz', '2002.csv.gz', '2003.csv.gz', '2004.csv.gz', '2005.csv.gz', '2006.csv.gz', '2007.csv.gz', '2008.csv.gz', '2009.csv.gz', '2010.csv.gz', '2011.csv.gz', '2012.csv.gz', '2013.csv.gz', '2014.csv.gz', '2015.csv.gz', '2016.csv.gz', '2017.csv.gz', '2018.csv.gz', '2019.csv.gz', '2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz', '2024.csv.gz', '2025.csv.gz']
[2025-07-05T11:18:19.287+0000] {logging_mixin.py:151} INFO - Looking for years: [2020, 2021, 2022, 2023]
[2025-07-05T11:18:19.287+0000] {logging_mixin.py:151} INFO - Filtered links: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T11:18:19.288+0000] {python.py:194} INFO - Done. Returned value was: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T11:18:19.386+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=list_files, execution_date=20250705T000000, start_date=20250705T111818, end_date=20250705T111819
[2025-07-05T11:18:19.571+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-05T11:18:19.668+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-05T11:32:33.087+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T11:32:33.090+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T11:32:33.091+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-05T11:32:33.096+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): list_files> on 2025-07-05 00:00:00+00:00
[2025-07-05T11:32:33.099+0000] {standard_task_runner.py:57} INFO - Started process 508 to run task
[2025-07-05T11:32:33.101+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'list_files', 'manual__2025-07-05T00:00:00+00:00', '--job-id', '65', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmpjhq59bq1']
[2025-07-05T11:32:33.103+0000] {standard_task_runner.py:85} INFO - Job 65: Subtask list_files
[2025-07-05T11:32:33.112+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-05T11:32:33.134+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [running]> on host 139cae0cce46
[2025-07-05T11:32:33.285+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='list_files' AIRFLOW_CTX_EXECUTION_DATE='2025-07-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-05T00:00:00+00:00'
[2025-07-05T11:32:33.289+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-05T11:32:34.890+0000] {logging_mixin.py:151} INFO - Response status: 200
[2025-07-05T11:32:34.891+0000] {logging_mixin.py:151} INFO - Response length: 37759
[2025-07-05T11:32:34.891+0000] {logging_mixin.py:151} INFO - Response preview: <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
 <head>
  <title>Index of /pub/data/ghcn/daily/by_year</title>
 </head>
 <body>
<h1>Index of /pub/data/ghcn/daily/by_year</h1>
  <table>
   <tr><th><a href="?C=N;O=D">Name</a></th><th><a href="?C=M;O=A">Last modified</a></th><th><a href="?C=S;O=A">Size</a></th><th><a href="?C=D;O=A">Description</a></th></tr>
   <tr><th colspan="4"><hr></th></tr>
<tr><td><a href="/pub/data/ghcn/daily/">Parent Directory</a></td><td>&nbsp;</td><td align
[2025-07-05T11:32:34.892+0000] {logging_mixin.py:151} INFO - Raw HTML sample: r>
<tr><td><a href="2020.csv.gz">2020.cs
[2025-07-05T11:32:34.892+0000] {logging_mixin.py:151} INFO - All links found: ['1750.csv.gz', '1763.csv.gz', '1764.csv.gz', '1765.csv.gz', '1766.csv.gz', '1767.csv.gz', '1768.csv.gz', '1769.csv.gz', '1770.csv.gz', '1771.csv.gz', '1772.csv.gz', '1773.csv.gz', '1774.csv.gz', '1775.csv.gz', '1776.csv.gz', '1777.csv.gz', '1778.csv.gz', '1779.csv.gz', '1780.csv.gz', '1781.csv.gz', '1782.csv.gz', '1783.csv.gz', '1784.csv.gz', '1785.csv.gz', '1786.csv.gz', '1787.csv.gz', '1788.csv.gz', '1789.csv.gz', '1790.csv.gz', '1791.csv.gz', '1792.csv.gz', '1793.csv.gz', '1794.csv.gz', '1795.csv.gz', '1796.csv.gz', '1797.csv.gz', '1798.csv.gz', '1799.csv.gz', '1800.csv.gz', '1801.csv.gz', '1802.csv.gz', '1803.csv.gz', '1804.csv.gz', '1805.csv.gz', '1806.csv.gz', '1807.csv.gz', '1808.csv.gz', '1809.csv.gz', '1810.csv.gz', '1811.csv.gz', '1812.csv.gz', '1813.csv.gz', '1814.csv.gz', '1815.csv.gz', '1816.csv.gz', '1817.csv.gz', '1818.csv.gz', '1819.csv.gz', '1820.csv.gz', '1821.csv.gz', '1822.csv.gz', '1823.csv.gz', '1824.csv.gz', '1825.csv.gz', '1826.csv.gz', '1827.csv.gz', '1828.csv.gz', '1829.csv.gz', '1830.csv.gz', '1831.csv.gz', '1832.csv.gz', '1833.csv.gz', '1834.csv.gz', '1835.csv.gz', '1836.csv.gz', '1837.csv.gz', '1838.csv.gz', '1839.csv.gz', '1840.csv.gz', '1841.csv.gz', '1842.csv.gz', '1843.csv.gz', '1844.csv.gz', '1845.csv.gz', '1846.csv.gz', '1847.csv.gz', '1848.csv.gz', '1849.csv.gz', '1850.csv.gz', '1851.csv.gz', '1852.csv.gz', '1853.csv.gz', '1854.csv.gz', '1855.csv.gz', '1856.csv.gz', '1857.csv.gz', '1858.csv.gz', '1859.csv.gz', '1860.csv.gz', '1861.csv.gz', '1862.csv.gz', '1863.csv.gz', '1864.csv.gz', '1865.csv.gz', '1866.csv.gz', '1867.csv.gz', '1868.csv.gz', '1869.csv.gz', '1870.csv.gz', '1871.csv.gz', '1872.csv.gz', '1873.csv.gz', '1874.csv.gz', '1875.csv.gz', '1876.csv.gz', '1877.csv.gz', '1878.csv.gz', '1879.csv.gz', '1880.csv.gz', '1881.csv.gz', '1882.csv.gz', '1883.csv.gz', '1884.csv.gz', '1885.csv.gz', '1886.csv.gz', '1887.csv.gz', '1888.csv.gz', '1889.csv.gz', '1890.csv.gz', '1891.csv.gz', '1892.csv.gz', '1893.csv.gz', '1894.csv.gz', '1895.csv.gz', '1896.csv.gz', '1897.csv.gz', '1898.csv.gz', '1899.csv.gz', '1900.csv.gz', '1901.csv.gz', '1902.csv.gz', '1903.csv.gz', '1904.csv.gz', '1905.csv.gz', '1906.csv.gz', '1907.csv.gz', '1908.csv.gz', '1909.csv.gz', '1910.csv.gz', '1911.csv.gz', '1912.csv.gz', '1913.csv.gz', '1914.csv.gz', '1915.csv.gz', '1916.csv.gz', '1917.csv.gz', '1918.csv.gz', '1919.csv.gz', '1920.csv.gz', '1921.csv.gz', '1922.csv.gz', '1923.csv.gz', '1924.csv.gz', '1925.csv.gz', '1926.csv.gz', '1927.csv.gz', '1928.csv.gz', '1929.csv.gz', '1930.csv.gz', '1931.csv.gz', '1932.csv.gz', '1933.csv.gz', '1934.csv.gz', '1935.csv.gz', '1936.csv.gz', '1937.csv.gz', '1938.csv.gz', '1939.csv.gz', '1940.csv.gz', '1941.csv.gz', '1942.csv.gz', '1943.csv.gz', '1944.csv.gz', '1945.csv.gz', '1946.csv.gz', '1947.csv.gz', '1948.csv.gz', '1949.csv.gz', '1950.csv.gz', '1951.csv.gz', '1952.csv.gz', '1953.csv.gz', '1954.csv.gz', '1955.csv.gz', '1956.csv.gz', '1957.csv.gz', '1958.csv.gz', '1959.csv.gz', '1960.csv.gz', '1961.csv.gz', '1962.csv.gz', '1963.csv.gz', '1964.csv.gz', '1965.csv.gz', '1966.csv.gz', '1967.csv.gz', '1968.csv.gz', '1969.csv.gz', '1970.csv.gz', '1971.csv.gz', '1972.csv.gz', '1973.csv.gz', '1974.csv.gz', '1975.csv.gz', '1976.csv.gz', '1977.csv.gz', '1978.csv.gz', '1979.csv.gz', '1980.csv.gz', '1981.csv.gz', '1982.csv.gz', '1983.csv.gz', '1984.csv.gz', '1985.csv.gz', '1986.csv.gz', '1987.csv.gz', '1988.csv.gz', '1989.csv.gz', '1990.csv.gz', '1991.csv.gz', '1992.csv.gz', '1993.csv.gz', '1994.csv.gz', '1995.csv.gz', '1996.csv.gz', '1997.csv.gz', '1998.csv.gz', '1999.csv.gz', '2000.csv.gz', '2001.csv.gz', '2002.csv.gz', '2003.csv.gz', '2004.csv.gz', '2005.csv.gz', '2006.csv.gz', '2007.csv.gz', '2008.csv.gz', '2009.csv.gz', '2010.csv.gz', '2011.csv.gz', '2012.csv.gz', '2013.csv.gz', '2014.csv.gz', '2015.csv.gz', '2016.csv.gz', '2017.csv.gz', '2018.csv.gz', '2019.csv.gz', '2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz', '2024.csv.gz', '2025.csv.gz']
[2025-07-05T11:32:34.893+0000] {logging_mixin.py:151} INFO - Looking for years: [2020, 2021, 2022, 2023]
[2025-07-05T11:32:34.893+0000] {logging_mixin.py:151} INFO - Filtered links: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T11:32:34.894+0000] {python.py:194} INFO - Done. Returned value was: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T11:32:34.914+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=weather_data_pipeline, task_id=list_files, execution_date=20250705T000000, start_date=20250705T113233, end_date=20250705T113234
[2025-07-05T11:32:34.949+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-05T11:32:34.971+0000] {taskinstance.py:2776} INFO - 4 downstream tasks scheduled from follow-on schedule check
[2025-07-05T11:35:38.507+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T11:35:38.511+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [queued]>
[2025-07-05T11:35:38.511+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2
[2025-07-05T11:35:38.516+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): list_files> on 2025-07-05 00:00:00+00:00
[2025-07-05T11:35:38.518+0000] {standard_task_runner.py:57} INFO - Started process 254 to run task
[2025-07-05T11:35:38.520+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'weather_data_pipeline', 'list_files', 'manual__2025-07-05T00:00:00+00:00', '--job-id', '71', '--raw', '--subdir', 'DAGS_FOLDER/weather_data_pipeline.py', '--cfg-path', '/tmp/tmpaq4w3_9g']
[2025-07-05T11:35:38.521+0000] {standard_task_runner.py:85} INFO - Job 71: Subtask list_files
[2025-07-05T11:35:38.528+0000] {logging_mixin.py:151} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-07-05T11:35:38.542+0000] {task_command.py:415} INFO - Running <TaskInstance: weather_data_pipeline.list_files manual__2025-07-05T00:00:00+00:00 [running]> on host 139cae0cce46
[2025-07-05T11:35:38.656+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='weather_data_pipeline' AIRFLOW_CTX_TASK_ID='list_files' AIRFLOW_CTX_EXECUTION_DATE='2025-07-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-05T00:00:00+00:00'
[2025-07-05T11:35:38.660+0000] {base.py:73} INFO - Using connection ID 'noaa_http' for task execution.
[2025-07-05T11:35:40.198+0000] {logging_mixin.py:151} INFO - Response status: 200
[2025-07-05T11:35:40.199+0000] {logging_mixin.py:151} INFO - Response length: 37759
[2025-07-05T11:35:40.199+0000] {logging_mixin.py:151} INFO - Response preview: <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
 <head>
  <title>Index of /pub/data/ghcn/daily/by_year</title>
 </head>
 <body>
<h1>Index of /pub/data/ghcn/daily/by_year</h1>
  <table>
   <tr><th><a href="?C=N;O=D">Name</a></th><th><a href="?C=M;O=A">Last modified</a></th><th><a href="?C=S;O=A">Size</a></th><th><a href="?C=D;O=A">Description</a></th></tr>
   <tr><th colspan="4"><hr></th></tr>
<tr><td><a href="/pub/data/ghcn/daily/">Parent Directory</a></td><td>&nbsp;</td><td align
[2025-07-05T11:35:40.200+0000] {logging_mixin.py:151} INFO - Raw HTML sample: r>
<tr><td><a href="2020.csv.gz">2020.cs
[2025-07-05T11:35:40.201+0000] {logging_mixin.py:151} INFO - All links found: ['1750.csv.gz', '1763.csv.gz', '1764.csv.gz', '1765.csv.gz', '1766.csv.gz', '1767.csv.gz', '1768.csv.gz', '1769.csv.gz', '1770.csv.gz', '1771.csv.gz', '1772.csv.gz', '1773.csv.gz', '1774.csv.gz', '1775.csv.gz', '1776.csv.gz', '1777.csv.gz', '1778.csv.gz', '1779.csv.gz', '1780.csv.gz', '1781.csv.gz', '1782.csv.gz', '1783.csv.gz', '1784.csv.gz', '1785.csv.gz', '1786.csv.gz', '1787.csv.gz', '1788.csv.gz', '1789.csv.gz', '1790.csv.gz', '1791.csv.gz', '1792.csv.gz', '1793.csv.gz', '1794.csv.gz', '1795.csv.gz', '1796.csv.gz', '1797.csv.gz', '1798.csv.gz', '1799.csv.gz', '1800.csv.gz', '1801.csv.gz', '1802.csv.gz', '1803.csv.gz', '1804.csv.gz', '1805.csv.gz', '1806.csv.gz', '1807.csv.gz', '1808.csv.gz', '1809.csv.gz', '1810.csv.gz', '1811.csv.gz', '1812.csv.gz', '1813.csv.gz', '1814.csv.gz', '1815.csv.gz', '1816.csv.gz', '1817.csv.gz', '1818.csv.gz', '1819.csv.gz', '1820.csv.gz', '1821.csv.gz', '1822.csv.gz', '1823.csv.gz', '1824.csv.gz', '1825.csv.gz', '1826.csv.gz', '1827.csv.gz', '1828.csv.gz', '1829.csv.gz', '1830.csv.gz', '1831.csv.gz', '1832.csv.gz', '1833.csv.gz', '1834.csv.gz', '1835.csv.gz', '1836.csv.gz', '1837.csv.gz', '1838.csv.gz', '1839.csv.gz', '1840.csv.gz', '1841.csv.gz', '1842.csv.gz', '1843.csv.gz', '1844.csv.gz', '1845.csv.gz', '1846.csv.gz', '1847.csv.gz', '1848.csv.gz', '1849.csv.gz', '1850.csv.gz', '1851.csv.gz', '1852.csv.gz', '1853.csv.gz', '1854.csv.gz', '1855.csv.gz', '1856.csv.gz', '1857.csv.gz', '1858.csv.gz', '1859.csv.gz', '1860.csv.gz', '1861.csv.gz', '1862.csv.gz', '1863.csv.gz', '1864.csv.gz', '1865.csv.gz', '1866.csv.gz', '1867.csv.gz', '1868.csv.gz', '1869.csv.gz', '1870.csv.gz', '1871.csv.gz', '1872.csv.gz', '1873.csv.gz', '1874.csv.gz', '1875.csv.gz', '1876.csv.gz', '1877.csv.gz', '1878.csv.gz', '1879.csv.gz', '1880.csv.gz', '1881.csv.gz', '1882.csv.gz', '1883.csv.gz', '1884.csv.gz', '1885.csv.gz', '1886.csv.gz', '1887.csv.gz', '1888.csv.gz', '1889.csv.gz', '1890.csv.gz', '1891.csv.gz', '1892.csv.gz', '1893.csv.gz', '1894.csv.gz', '1895.csv.gz', '1896.csv.gz', '1897.csv.gz', '1898.csv.gz', '1899.csv.gz', '1900.csv.gz', '1901.csv.gz', '1902.csv.gz', '1903.csv.gz', '1904.csv.gz', '1905.csv.gz', '1906.csv.gz', '1907.csv.gz', '1908.csv.gz', '1909.csv.gz', '1910.csv.gz', '1911.csv.gz', '1912.csv.gz', '1913.csv.gz', '1914.csv.gz', '1915.csv.gz', '1916.csv.gz', '1917.csv.gz', '1918.csv.gz', '1919.csv.gz', '1920.csv.gz', '1921.csv.gz', '1922.csv.gz', '1923.csv.gz', '1924.csv.gz', '1925.csv.gz', '1926.csv.gz', '1927.csv.gz', '1928.csv.gz', '1929.csv.gz', '1930.csv.gz', '1931.csv.gz', '1932.csv.gz', '1933.csv.gz', '1934.csv.gz', '1935.csv.gz', '1936.csv.gz', '1937.csv.gz', '1938.csv.gz', '1939.csv.gz', '1940.csv.gz', '1941.csv.gz', '1942.csv.gz', '1943.csv.gz', '1944.csv.gz', '1945.csv.gz', '1946.csv.gz', '1947.csv.gz', '1948.csv.gz', '1949.csv.gz', '1950.csv.gz', '1951.csv.gz', '1952.csv.gz', '1953.csv.gz', '1954.csv.gz', '1955.csv.gz', '1956.csv.gz', '1957.csv.gz', '1958.csv.gz', '1959.csv.gz', '1960.csv.gz', '1961.csv.gz', '1962.csv.gz', '1963.csv.gz', '1964.csv.gz', '1965.csv.gz', '1966.csv.gz', '1967.csv.gz', '1968.csv.gz', '1969.csv.gz', '1970.csv.gz', '1971.csv.gz', '1972.csv.gz', '1973.csv.gz', '1974.csv.gz', '1975.csv.gz', '1976.csv.gz', '1977.csv.gz', '1978.csv.gz', '1979.csv.gz', '1980.csv.gz', '1981.csv.gz', '1982.csv.gz', '1983.csv.gz', '1984.csv.gz', '1985.csv.gz', '1986.csv.gz', '1987.csv.gz', '1988.csv.gz', '1989.csv.gz', '1990.csv.gz', '1991.csv.gz', '1992.csv.gz', '1993.csv.gz', '1994.csv.gz', '1995.csv.gz', '1996.csv.gz', '1997.csv.gz', '1998.csv.gz', '1999.csv.gz', '2000.csv.gz', '2001.csv.gz', '2002.csv.gz', '2003.csv.gz', '2004.csv.gz', '2005.csv.gz', '2006.csv.gz', '2007.csv.gz', '2008.csv.gz', '2009.csv.gz', '2010.csv.gz', '2011.csv.gz', '2012.csv.gz', '2013.csv.gz', '2014.csv.gz', '2015.csv.gz', '2016.csv.gz', '2017.csv.gz', '2018.csv.gz', '2019.csv.gz', '2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz', '2024.csv.gz', '2025.csv.gz']
[2025-07-05T11:35:40.201+0000] {logging_mixin.py:151} INFO - Looking for years: [2020, 2021, 2022, 2023]
[2025-07-05T11:35:40.201+0000] {logging_mixin.py:151} INFO - Filtered links: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T11:35:40.203+0000] {python.py:194} INFO - Done. Returned value was: ['2020.csv.gz', '2021.csv.gz', '2022.csv.gz', '2023.csv.gz']
[2025-07-05T11:35:40.216+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "xcom_pkey"
DETAIL:  Key (dag_run_id, task_id, map_index, key)=(19, list_files, -1, return_value) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2477, in xcom_push
    XCom.set(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/xcom.py", line 273, in set
    session.flush()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3589, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "xcom_pkey"
DETAIL:  Key (dag_run_id, task_id, map_index, key)=(19, list_files, -1, return_value) already exists.

[SQL: INSERT INTO xcom (dag_run_id, task_id, map_index, key, dag_id, run_id, value, timestamp) VALUES (%(dag_run_id)s, %(task_id)s, %(map_index)s, %(key)s, %(dag_id)s, %(run_id)s, %(value)s, %(timestamp)s)]
[parameters: {'dag_run_id': 19, 'task_id': 'list_files', 'map_index': -1, 'key': 'return_value', 'dag_id': 'weather_data_pipeline', 'run_id': 'manual__2025-07-05T00:00:00+00:00', 'value': <psycopg2.extensions.Binary object at 0xffff5a1a9d20>, 'timestamp': datetime.datetime(2025, 7, 5, 11, 35, 40, 215319, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2025-07-05T11:35:40.227+0000] {taskinstance.py:1398} INFO - Marking task as UP_FOR_RETRY. dag_id=weather_data_pipeline, task_id=list_files, execution_date=20250705T000000, start_date=20250705T113538, end_date=20250705T113540
[2025-07-05T11:35:40.236+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 71 for task list_files ((psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "xcom_pkey"
DETAIL:  Key (dag_run_id, task_id, map_index, key)=(19, list_files, -1, return_value) already exists.

[SQL: INSERT INTO xcom (dag_run_id, task_id, map_index, key, dag_id, run_id, value, timestamp) VALUES (%(dag_run_id)s, %(task_id)s, %(map_index)s, %(key)s, %(dag_id)s, %(run_id)s, %(value)s, %(timestamp)s)]
[parameters: {'dag_run_id': 19, 'task_id': 'list_files', 'map_index': -1, 'key': 'return_value', 'dag_id': 'weather_data_pipeline', 'run_id': 'manual__2025-07-05T00:00:00+00:00', 'value': <psycopg2.extensions.Binary object at 0xffff5a1a9d20>, 'timestamp': datetime.datetime(2025, 7, 5, 11, 35, 40, 215319, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 254)
[2025-07-05T11:35:40.283+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2025-07-05T11:35:40.295+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
